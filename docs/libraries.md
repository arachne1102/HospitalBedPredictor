# 필수 라이브러리

프로젝트의 현재 단계와 향후 계획에 따라 필요한 라이브러리를 정리하였습니다.

## 데이터 수집 단계

### 1. mysql-connector-python

- 역할: Python과 MySQL 데이터베이스를 연결합니다.
- 사용 부분:
  - 데이터베이스 연결: MySQL에서 데이터를 조회하고 가져옵니다.

### 2. sshtunnel

- 역할: SSH 터널링을 통해 원격 서버와의 연결을 지원합니다.
- 사용 부분:
  - SSH 터널링: 원격 데이터베이스에 안전하게 접속하기 위해 사용합니다.

### 3. python-dotenv

- 역할: 환경 변수 관리를 도와줍니다.
- 사용 부분:
  - 환경 변수 로드: `.env` 파일에서 설정을 불러옵니다.

## 향후 필요 라이브러리

### 4. pandas

- 역할: 데이터 처리 및 분석의 핵심 라이브러리
- 사용 예정 부분:
  - 데이터 로딩 및 전처리: CSV 파일 및 데이터베이스에서 데이터를 불러와 `DataFrame` 형태로 관리하고 전처리합니다.

### 5. numpy

- 역할: 고성능의 수치 계산 및 배열 연산 제공
- 사용 예정 부분:
  - 수치 연산: 수학적 계산 및 통계 분석 수행

### 6. scikit-learn

- 역할: 머신러닝 알고리즘과 데이터 전처리 도구 제공
- 사용 예정 부분:
  - 데이터 전처리: 스케일링, 인코딩 등
  - 모델 구현 및 평가: 머신러닝 모델의 구현과 성능 평가

### 7. statsmodels

- 역할: 통계적 모델링 및 시계열 분석 라이브러리
- 사용 예정 부분:
  - 시계열 모델링: ARIMA 등 모델을 사용하여 시계열 데이터를 분석

### 8. Prophet

- 역할: 시계열 예측을 위한 라이브러리
- 사용 예정 부분:
  - 시계열 예측: 추세와 계절성을 고려한 예측 모델링

### 9. seaborn

- 역할: 데이터 시각화를 위한 라이브러리
- 사용 예정 부분:
  - 결과 시각화: 예측 결과를 그래프로 표현하여 이해를 돕습니다.
  - **참고:** Seaborn은 Matplotlib 기반으로 구축되어 있으며, Seaborn을 설치하면 Matplotlib도 함께 설치됩니다.

### 10. tensorflow

- 역할: 딥러닝 모델 구축 및 학습
- 사용 예정 부분:
  - LSTM 모델 구현: 복잡한 시계열 패턴을 학습하여 예측 성능을 향상시킵니다.
  - **참고:** TensorFlow 2.x 버전부터 Keras가 통합되어 있으므로, 별도의 Keras 설치가 필요하지 않습니다.

### 11. Optuna

- 역할: 하이퍼파라미터 최적화 도구
- 사용 예정 부분:
  - 모델 성능 향상: 최적의 하이퍼파라미터를 자동으로 탐색하여 모델의 성능을 개선합니다.
  - **참고:** 하이퍼파라미터 최적화를 진행할 계획이 있다면 포함합니다.

## 설치 방법

모든 필요한 라이브러리는 `requirements.txt` 파일에 명시되어 있으며, 다음 명령어로 설치할 수 있습니다.

```bash
pip install -r requirements.txt
